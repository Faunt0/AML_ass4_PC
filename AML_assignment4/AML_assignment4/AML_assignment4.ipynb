{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning - programming assignment 4\n",
    "\n",
    "*Due: Friday January 24*\n",
    "\n",
    "*Grading: 10 points total*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please fill in:**\n",
    "* Hein van Rooij (6706479)\n",
    "* Lex Klaassen (1345974)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further instructions:\n",
    "* Code quality is considered during the assessment. Use sensible variable names, and make sure your code is properly commented.\n",
    "* Submit your code in Blackboard using one of your accounts; we will put the grade in Blackboard for the other team member as well.\n",
    "* Make sure to name the submitted file according to your and your collaborators last name. (`submitter_collaborator.ipynb`)\n",
    "* **Failure to follow these instructions can affect the assignment grade.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the PC algorithm\n",
    "In this assignment, you will complete an implementation of the PC algorithm. After that, you will use it to discover causal relations in a data set. Each of these two parts is worth 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PC algorithm will need to keep track of a PDAG. We will represent this PDAG by a numpy array `G` of booleans.\n",
    "\n",
    "The matrix `G` represents a graph as follows:\n",
    "* For all `x`, `G[x,x] == False`\n",
    "* `G[x,y] == False` and `G[y,x] == False` means: no edge between x and y\n",
    "* `G[x,y] == True` and `G[y,x] == True` means: an undirected edge x&mdash;y\n",
    "* `G[x,y] == True` and `G[y,x] == False`means: a directed edge x$\\to$y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import graphviz\n",
    "\n",
    "from AML_assignment4_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `graphviz` to save graphs to different file formats, or show them directly in the notebook. The function `graph_to_graphviz(G, node_names)` (from the file `AML_assignment4_util.py`) converts a numpy array of the form described above to a graph in graphviz format. It requires the `Graphviz` program to be installed: see the instructions on Blackboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"440pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 440.00 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-40 436,-40 436,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"153\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"153\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.34,-18C71.92,-18 95.04,-18 114.47,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"114.2,-21.5 124.2,-18 114.2,-14.5 114.2,-21.5\"/>\n",
       "</g>\n",
       "<!-- Z -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Z</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"279\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"279\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Z</text>\n",
       "</g>\n",
       "<!-- Z&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Z&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.66,-18C234.08,-18 210.96,-18 191.53,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191.8,-14.5 181.8,-18 191.8,-21.5 191.8,-14.5\"/>\n",
       "</g>\n",
       "<!-- W -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>W</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"405\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"405\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">W</text>\n",
       "</g>\n",
       "<!-- Z&#45;&gt;W -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Z&#45;&gt;W</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M306.34,-18C327.47,-18 356.59,-18 377.71,-18\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fb745714c20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstration of graph_to_graphviz:\n",
    "node_names = ['X', 'Y', 'Z', 'W']\n",
    "G1 = np.zeros((4,4), dtype=bool)\n",
    "G1[0,1] = G1[2,1] = True # two directed edges\n",
    "G1[2,3] = G1[3,2] = True # an undirected edge\n",
    "d = graph_to_graphviz(G1, node_names)\n",
    "d # must be final line of code block to be displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a Python class for performing the PC algorithm (when an object of this class is created and its `run` function is called). Add the missing code for phase 2, and implement phases 3 and 4. Do not modify other code! In the next section, you'll find some test cases to see if your code runs without errors and does what you expect it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True False False]\n",
      " [False False False False]\n",
      " [False  True False  True]\n",
      " [False False  True False]]\n",
      "[ True False  True False]\n",
      "[0, 2]\n",
      "[(False, True, False), (False, True, False), (False, False, False), (True, False, False)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# G1 = np.zeros((4,4), dtype=bool)\n",
    "print(G1)\n",
    "print(G1[:, 1])\n",
    "\n",
    "indexed = [i for i, x in enumerate(G1[:, 1]) if x]\n",
    "print(indexed)\n",
    "print(list(itertools.combinations(G1[0, :], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PC_algorithm:\n",
    "    def __init__(self, independence_tester, verbose=1):\n",
    "        # verbose can be 0 (silent), 1 (report independences), or 2 (also report dependences)\n",
    "        self.independence_tester = independence_tester\n",
    "        self.n = independence_tester.n_observed\n",
    "        self.node_names = independence_tester.node_names\n",
    "        self.verbose = verbose\n",
    "        self.G = np.logical_not(np.eye(self.n, dtype=bool))\n",
    "        self.sepset = dict()\n",
    "    \n",
    "    def skeleton_search(self):\n",
    "        # PHASE II: Skeleton search\n",
    "        # Note: Adj(X) in the slides means: all nodes adjacent to X in the current graph G\n",
    "        for k in range(self.n-1):\n",
    "            for x in range(self.n):\n",
    "                for y in range(self.n):\n",
    "                    if not self.G[x,y]:\n",
    "                        continue\n",
    "                    # Try all subsets S of Adj(x) \\ {y} with |S|=k.\n",
    "                    # Hint: use itertools.combinations\n",
    "\n",
    "                    # TASK 1: Your code here (1 point)\n",
    "                    # Our code\n",
    "                    # find Adj(x) \\ {y}\n",
    "                    adjx = self.G[x, :]\n",
    "                    del adjx[y]\n",
    "\n",
    "                    for S in itertools.combinations(adjx, k): # replace this line by your code\n",
    "                        indep = self.independence_tester.test_independence(x, y, S)\n",
    "                        if indep:\n",
    "                            if self.verbose >= 1:\n",
    "                                print(f\"independence found: \"\n",
    "                                      f\"{self.node_names[x]} and {self.node_names[y]} \"\n",
    "                                      f\"given {{{\", \".join([self.node_names[v] for v in S])}}}\")\n",
    "                            # Remove this edge.\n",
    "                            self.G[x,y] = self.G[y,x] = False\n",
    "                            # We use frozensets as keys in the dictionary self.sepset,\n",
    "                            # because ordinary sets can't be used as keys to dictionaries.\n",
    "                            self.sepset[frozenset([x,y])] = S\n",
    "                            break\n",
    "                        else:\n",
    "                            if self.verbose >= 2:\n",
    "                                print(f\"dependence found: \"\n",
    "                                      f\"{self.node_names[x]} and {self.node_names[y]} \"\n",
    "                                      f\"given {{{\", \".join([self.node_names[v] for v in S])}}}\")\n",
    "\n",
    "            # Do we need to continue with larger k?\n",
    "            max_S_size = np.sum(self.G, axis=0) - 1\n",
    "            if np.all(max_S_size < k + 1):\n",
    "                break\n",
    "        return\n",
    "\n",
    "    def orient_v_structures(self):\n",
    "        # PHASE III: Orient v-structures\n",
    "\n",
    "        # Something to watch out for:\n",
    "        # If the data are not faithful to any DAG, the algorithm may end up trying\n",
    "        # to orient a single edge in two different ways. You can choose either\n",
    "        # orientation if this happens. But make sure not to accidentally delete such an edge!\n",
    "\n",
    "        # TASK 2: Your code here (2 points)\n",
    "        # Our code\n",
    "        for x in range(self.n):\n",
    "            for y in range(self.n):\n",
    "                # find all nodes adjacent to both x and y\n",
    "                adjx = self.G[x, :] # this might not be taking into account the directedness of the edges, this only looks at directed edges from x, therefore this is not the complete set of adjacent nodes\n",
    "                adjy = self.G[y, :]\n",
    "\n",
    "                # misschien alleen de indexen overhouden\n",
    "                z_nodes = set.intersection(adjx, adjy)\n",
    "                for z in z_nodes:\n",
    "                    if z not in self.sepset[frozenset([x,y])]:\n",
    "                        self.G[x, z] = True\n",
    "                        self.G[y, z] = True\n",
    "    \n",
    "    def orientation_rules(self):\n",
    "        # PHASE IV: Orientation rules\n",
    "\n",
    "        # TASK 3: Your code here (2 points)\n",
    "        # Our code\n",
    "        # if there is a directed edge from Z into X and an undirected edge between X and Y and Z and Y are not adjacent then make the directed edge X to Y\n",
    "\n",
    "        # while:\n",
    "        for x in range(self.n):\n",
    "            for y in range(self.n):\n",
    "                # make sure we are looking at an undirected edge between x and y\n",
    "                if self.G[x, y] == self.G[y, x]:\n",
    "\n",
    "                    # rule 1\n",
    "                    z_to_x = [i for i, z in enumerate(self.G[:, x]) if z] # get the indexes of the nodes going into x\n",
    "                    for z in z_to_x:\n",
    "                        # if there is no edge to y but z is pointing to x then we have rule 1\n",
    "                        if not self.G[z, y] and not self.G[y, z]:\n",
    "                            self.G[x, y] = True\n",
    "                            break # cleanliness\n",
    "                    \n",
    "                    # rule 2\n",
    "                    x_to_z = [i for i, z in enumerate(self.G[x, :]) if z] # get all nodes that x points to\n",
    "                    for z in x_to_z:\n",
    "                        if self.G[z, y]:\n",
    "                            self.G[x, y] = True\n",
    "                            break\n",
    "                    \n",
    "                    # rule 3\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return\n",
    "\n",
    "    def run(self):\n",
    "        # The initialization step has already been performed by the __init__ method.\n",
    "        # Perform the other phases one by one. Each of the following functions\n",
    "        # modifies self.G, which represents the graph.\n",
    "        self.skeleton_search()\n",
    "        self.orient_v_structures()\n",
    "        self.orientation_rules()\n",
    "\n",
    "        return self.G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the PC implementation\n",
    "\n",
    "To verify that the algorithm is working correctly, we will feed it output from an *oracle* instead of conditional independence test results from a data set. The oracle knows what the true DAG is, and mimics the conditional independence test results that we would get for data that is Markov and faithful to that DAG. In this situation, the PC algorithm will recover the Markov equivalence class of the true DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndependenceOracle:\n",
    "    def __init__(self, true_G, node_names, n_observed=None):\n",
    "        self.G = true_G\n",
    "        self.n = true_G.shape[0]\n",
    "        self.n_observed = n_observed if n_observed is not None else self.n\n",
    "        self.node_names = node_names\n",
    "    def test_independence(self, x, y, S):\n",
    "        S_mask = np.zeros(self.n, dtype=bool)\n",
    "        np.put(S_mask, S, True)\n",
    "        return is_d_separated(self.G, x, y, S_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the output of PC to the oracle's true DAG for the DAG `G1` we saw before, and for several other DAGs. (You can add more tests to help chase down any bugs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = IndependenceOracle(G1, node_names)\n",
    "A = PC_algorithm(oracle, verbose=2)\n",
    "G = A.run()\n",
    "print(\"PASS\" if np.all(G == G1) else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = np.zeros((4,4), dtype=bool)\n",
    "G2[0,2] = G2[1,2] = G2[2,3] = True\n",
    "graph_to_graphviz(G2, node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = IndependenceOracle(G2, node_names)\n",
    "A = PC_algorithm(oracle)\n",
    "G = A.run()\n",
    "print(\"PASS\" if np.all(G == G2) else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G3 = np.zeros((4,4), dtype=bool)\n",
    "G3[0,2] = G3[1,2] = G3[1,3] = G3[2,3] = True\n",
    "graph_to_graphviz(G3, node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = IndependenceOracle(G3, node_names)\n",
    "A = PC_algorithm(oracle)\n",
    "G = A.run()\n",
    "print(\"PASS\" if np.all(G == G3) else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G4 = np.logical_not(np.eye(4, dtype=bool))\n",
    "G4[0,1] = G4[1,0] = False\n",
    "G4[3,0] = G4[3,1] = G4[3,2] = False\n",
    "graph_to_graphviz(G4, node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = IndependenceOracle(G4, node_names)\n",
    "A = PC_algorithm(oracle)\n",
    "G = A.run()\n",
    "print(\"PASS\" if np.all(G == G4) else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a case for which no DAG exists that is Markov and faithful to the distribution.\n",
    "# L is a latent variable that the PC algorithm won't know about. PC's output should be either\n",
    "# X --> Y --> Z <-- W or\n",
    "# X --> Y <-- Z <-- W.\n",
    "# If there is no edge between Y and Z in your output, this most likely indicates a bug in\n",
    "# your implementation of phase III.\n",
    "G5 = np.zeros((5,5), dtype=bool)\n",
    "G5[0,1] = G5[4,1] = True\n",
    "G5[3,2] = G5[4,2] = True\n",
    "graph_to_graphviz(G5, ['X', 'Y', 'Z', 'W', 'L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = IndependenceOracle(G5, node_names, n_observed = 4)\n",
    "A = PC_algorithm(oracle)\n",
    "G = A.run()\n",
    "print(\"PASS\" if G[0,1] and G[3,2] and (G[1,2] or G[2,1]) and np.sum(np.logical_or(G, G.T)) == 6 else \"FAIL\")\n",
    "graph_to_graphviz(G, oracle.node_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running PC on data\n",
    "In this second part of the assignment, you will apply the PC algorithm to the biological dataset of Sachs et al. (2005). In this dataset, the columns represent 11 different proteins, which were measured in thousands of human immune system cells. Each row is a single cell. The cells were prepared in different ways, by adding different chemicals some time before the measurements were made. A twelfth column, labeled `experiment`, indicates in which way that cell was prepared. We can think of `experiment=1` as denoting the observational data, and other values of `experiment` (2 through 14) as various interventional datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_data = pd.read_csv(\"sachs2005_combined.csv\", sep='\\t')\n",
    "# Transform all columns except 'experiment' by taking the logarithm of 10 + the original value\n",
    "all_data.loc[:, all_data.columns != 'experiment'] = np.log(10 + all_data.loc[:, all_data.columns != 'experiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply the PC algorithm to just the observational data.\n",
    "\n",
    "Make a new dataframe containing only the data where experiment equals 1. Remove the `experiment` column from this dataframe. Check the shape of your dataframe: it should be `(853, 11)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 4: Your code here (0.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the PC algorithm on data, we need to perform (conditional) independence tests. The code below implements a simple test (based on [Spearman correlation](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient)). It is not a perfect match for our data, but the alternatives (such as `CMIknn` (Runge, 2018)) are orders of magnitude slower, while Spearman correlation usually already gives decent results.\n",
    "\n",
    "As a statistical test, a conditional independence test works by computing a p-value. If a conditional independence exists, this p-value will be approximately uniformly distributed on the interval between 0 and 1. If the variables being tested are conditionally dependent, the p-value will be close to 0. PC wants to know a binary answer, so we will pick some threshold alpha and declare an independence if the p-value is larger than alpha.\n",
    "\n",
    "In statistical testing, alpha is often taken to be 0.05 or smaller. For PC, it may be more appropriate to pick a larger alpha instead. This is because as soon as PC finds a (conditional) independence between two variables, it will delete the edge between them and do no more tests between those two variables. If this happens while it shouldn't have, PC can't put the edge back. But in the reverse situation, if PC leaves an edge in place while it should have deleted it, there is still a possibility that the edge will be deleted later, when another test between those two variables reports a more convincing independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import beta\n",
    "\n",
    "class IndependenceTester:\n",
    "    def __init__(self, data, alpha, verbose=2, method='spearman', n_observed=None):\n",
    "        # data: a pandas dataframe\n",
    "        # alpha: the significance level to which the p-values are compared\n",
    "\n",
    "        self.covariance_matrix = data.corr(method).to_numpy()\n",
    "        self.num_samples = data.shape[0]\n",
    "        self.n = data.shape[1]\n",
    "        self.n_observed = n_observed if n_observed is not None else self.n\n",
    "        self.verbose = verbose\n",
    "        self.node_names = data.columns\n",
    "        self.alpha = alpha\n",
    "    def test_independence(self, x, y, S):\n",
    "        # Compute the partial correlation of x and y given S by inverting a submatrix of the covariance matrix.\n",
    "        xyS = [x, y]\n",
    "        xyS.extend(S)\n",
    "        precision_matrix = np.linalg.inv(self.covariance_matrix[np.ix_(xyS, xyS)])\n",
    "        corr = -precision_matrix[0,1] / math.sqrt(precision_matrix[0,0] * precision_matrix[1,1])\n",
    "        # Compute the p-value as in the scipy manual for scipy.stats.pearsonr.\n",
    "        dist = beta(self.num_samples / 2 - 1, self.num_samples / 2 - 1, loc=-1, scale=2)\n",
    "        pval = 2 * dist.cdf(-abs(corr))\n",
    "        test_result = pval > self.alpha\n",
    "        if self.verbose >= 2 or (self.verbose >= 1 and test_result):\n",
    "            print(f\"test: {self.node_names[x]} and {self.node_names[y]} \"\n",
    "                  f\"given {{{\", \".join([self.node_names[v] for v in S])}}} \"\n",
    "                  f\"-> pval={pval}\")\n",
    "        return test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an IndependenceTester object (which works similarly to the IndependenceOracle we used earlier), run the PC algorithm on the observational data. Display the graph that comes out. You may experiment with different values of alpha; the graph you get should either be connected (i.e. consist of one [connected component](https://en.wikipedia.org/wiki/Component_%28graph_theory%29)), or have just two or three connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 5: Your code here (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what else is in the dataset: the interventional data corresponding to different experiments. The PC algorithm did not look at this part of the dataset, but these additional experiments can obviously provide valuable information about the causal graph. In the following questions, we will investigate two examples of this. We will use the output of the PC algorithm that you obtained above to give us a rough idea of what the causal graph might look like. **So don't rerun the algorithm when answering the questions below!**\n",
    "\n",
    "The interventions in these experiment are not perfect interventions: they change the structural equation of a variable, but not by setting it to a constant. The new structural equation in the intervened model may still include all variables that were there in the original model. So in the graph of the intervened model, all arrows will still be there.\n",
    "\n",
    "Further, some of the interventions change not one, but multiple structural equations.\n",
    "\n",
    "For some of the interventions in the data, here is what they do according to many (but not all) experts:\n",
    "* experiment 5 adds the substance psitectorigenin, which modifies the amount of PIP2;\n",
    "* experiment 6 adds the substance U0126, which increases the *activity* of pmek. This means that the amount of pmek is not changed by the intervention, but for all *children* of pmek in the causal model, the structural equation changes to reflect that pmek now has a stronger effect on them. pmek is believed to have only one child in the true causal model, namely perk.\n",
    "\n",
    "(Source: Mooij et al., 2020, specifically Tables 2 & 3 and Figure 38(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two new dataframes, one containing all data from experiments 1 and 5, and one with the data from experiments 1 and 6. These dataframes should still have an `experiment` column, so that you can tell for each row whether it came from the observational or the interventional dataset. The questions refer to these dataframes and to the output of the PC algorithm you obtained above. (Do not run the PC algorithm on these dataframes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 6: Your code here (0.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7 (1.5 points)**: In the dataframe for experiments 1 and 5, look at PIP2 and a variable adjacent to it in the output of PC (if there is more than one, pick one). Using about 200 words, answer the following questions: Based on looking at one or more plots (like scatterplots or histograms), which do you find more likely: that psitectorigenin directly modifies PIP2, or the neighbouring variable, or both? And what does the data for the two experiments seem to say about the direction of the arrow between PIP2 and this neighbour?\n",
    "\n",
    "Insert one or more markdown and code boxes below here to give your answer and the plots you base your answer on. (Please put your answer in markdown boxes, not as comments in your code!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8 (1.5 points)**: In the dataframe for experiments 1 and 6, look at perk, pmek, and any (other) variables adjacent to pmek in the output of PC. Assume it is true that adding U0126 produces an intervention on the *activity* of pmek. What would you expect to see in the data if the graph found by PC was correct? Would you propose any changes to that graph based on the data?\n",
    "\n",
    "Again put your answer (about 200 words) with accompanying plots in new boxes below here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You are almost done! Before handing in, make sure that the code you hand in works, and that all plots are shown. **Submit just one file per team.** Name the submitted file according to your and your collaborator's last name (`submitter_collaborator.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* J. M. Mooij, S. Magliacane, and T. Claassen, \"Joint Causal Inference from Multiple Contexts,\" [JMLR 21(99):1−108](https://jmlr.org/papers/v21/17-123.html), 2020.\n",
    "* J. Runge, \"Conditional Independence Testing Based on a Nearest-Neighbor Estimator of Conditional Mutual Information\" In Proceedings of the 21st International Conference on Artificial Intelligence and Statistics, http://proceedings.mlr.press/v84/runge18a.html, 2018.\n",
    "* K. Sachs, O. Perez, D. Pe’er, D. A. Lauffenburger, and G. P. Nolan, \"Causal protein-signaling networks derived from multiparameter single-cell data,\" Science, vol. 308, no. 5721, pp. 523–529, 2005."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
